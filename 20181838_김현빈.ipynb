{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "86ySYK-0xToN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "# Install sentencepiece to use the pretrained model\n",
        "!pip install sentencepiece\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "from matplotlib.pyplot import imshow,cm\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "import csv\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "I6g53Cg0uYcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ySYK-0xToN"
      },
      "source": [
        "## Download Google Font\n",
        "* The location where the fonts will be stored should be **/usr/share/fonts/truetype/google-fonts/**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMCLOf0IkBIH"
      },
      "outputs": [],
      "source": [
        "_wgeturl=\"https://github.com/google/fonts/archive/main.tar.gz\"\n",
        "_gf=\"google-fonts\"\n",
        "\n",
        "!echo \"Connecting to Github server to download fonts...\"\n",
        "!wget \"https://github.com/google/fonts/archive/main.tar.gz\" -O google-fonts.tar.gz\n",
        "\n",
        "!echo \"Extracting the downloaded archive...\"\n",
        "!tar -zxvf google-fonts.tar.gz\n",
        "\n",
        "!echo \"Creating the /usr/share/fonts/truetype/$_gf folder\"\n",
        "!sudo mkdir -p /usr/share/fonts/truetype/$_gf\n",
        "\n",
        "!echo \"Installing all .ttf fonts in /usr/share/fonts/truetype/$_gf\"\n",
        "!find $PWD/fonts-main/ -name \"*.ttf\" -exec sudo install -m644 {} /usr/share/fonts/truetype/google-fonts/ \\; || echo \"An error occured, please run this script again.\"\n",
        "\n",
        "!echo \"Updating the font cache\"\n",
        "!fc-cache -f\n",
        "\n",
        "!echo \"Done. Now you can delete the tarball file $_gf.tar.gz if you wish.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSLPdcDxcvh"
      },
      "source": [
        "* Find specific font you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt_edqCgmnwo"
      },
      "outputs": [],
      "source": [
        "!find /usr/share/fonts/truetype/google-fonts/ -name \"Roboto*\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Generate Dataset\n",
        "We have to generate data to train the model.\n",
        "We generate four types of image data file.\n",
        "\n",
        "Each type is named **pure,blur,gaussian,blur+gaussian.**\n",
        "\n",
        "\n",
        "The location where the type of data will be stored should be **/data**. "
      ],
      "metadata": {
        "id": "e1902oLpvndv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set directory to save the data file\n",
        "!mkdir data"
      ],
      "metadata": {
        "id": "xL9K6SVVu29A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB9ldjePuQ23"
      },
      "outputs": [],
      "source": [
        "def generate_gaussian_noise(image):\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    mean = 0\n",
        "    sigma = 10\n",
        "    gaussian = np.random.normal(mean, sigma, (image.shape[0],image.shape[1]))\n",
        "    noisy_image = np.zeros(image.shape, np.float32)\n",
        "    noisy_image[:,:,0] = (image[:,:,0]+gaussian)/(np.max(gaussian)+255)*255\n",
        "    noisy_image[:,:,1] = (image[:,:,1]+gaussian)/(np.max(gaussian)+255)*255\n",
        "    noisy_image[:,:,2] = (image[:,:,2]+gaussian)/(np.max(gaussian)+255)*255\n",
        "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
        "    noisy_image = noisy_image.astype(np.uint8)\n",
        "    return noisy_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ImageGenerator(word_list, data_type = 'pure', #is_rand=False, is_gaussian=False,\\\n",
        "                   background='white',fill=(0,0,0),\\\n",
        "                   font_idx=0,num_of_generated_samples=0):\n",
        "\n",
        "    from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "    from matplotlib.pyplot import imshow,cm\n",
        "\n",
        "    import numpy as np\n",
        "    import random\n",
        "    import cv2\n",
        "    import time\n",
        "\n",
        "    '''\n",
        "    background='white'\n",
        "    fill=(0,0,0)\n",
        "    is_rand = True\n",
        "    is_gaussian = True\n",
        "    word_list = [\"asd\",\"qwer\",\"ejhjdwf\"]\n",
        "    '''\n",
        "    type_dict = {'pure':[False, False],\\\n",
        "                 'gaussian':[False, True],\\\n",
        "                 'blur':[True, False],\\\n",
        "                 'blur+gaussian':[True, True]}\n",
        "    is_rand, is_gaussian = type_dict[data_type]\n",
        "    font_list = ['/usr/share/fonts/truetype/google-fonts/RobotoMono[wght].ttf',\\\n",
        "                '/usr/share/fonts/truetype/google-fonts/MontserratAlternates-Medium.ttf',\\\n",
        "                '/usr/share/fonts/truetype/google-fonts/KdamThmorPro-Regular.ttf',\\\n",
        "                '/usr/share/fonts/truetype/google-fonts/Joan-Regular.ttf',\\\n",
        "                '/usr/share/fonts/truetype/google-fonts/Roboto-Bold.ttf']\n",
        "    random.seed(time.time())\n",
        "    string = \"\"\n",
        "    for item in word_list:\n",
        "        string = string + item + \" \"\n",
        "    #print(string)\n",
        "\n",
        "    font_type = font_list[font_idx%5]\n",
        "    font_size = 28\n",
        "    font = ImageFont.truetype(font_type,size = font_size)\n",
        "\n",
        "    string_size = font.getsize(string)\n",
        "    height = 64\n",
        "    #print(string_size)\n",
        "\n",
        "\n",
        "    x_pos = len(word_list)\n",
        "    y_pos= 16\n",
        "    image = Image.new('RGB',(string_size[0]+len(word_list), height), color = background)\n",
        "    imageDraw = ImageDraw.Draw(image)\n",
        "    #print(word_list)\n",
        "    blurr_list = []\n",
        "    for item in word_list:\n",
        "        xx_pos = x_pos\n",
        "        for char in item:\n",
        "            rand = 1\n",
        "            if is_rand==True:\n",
        "                rand = int(random.uniform(0,5))\n",
        "            if rand==0:\n",
        "                blurr_list.append([xx_pos, font.getsize(char)[0]])\n",
        "            xx_pos = xx_pos + font.getsize(char)[0] # font.getsize >> [width, height]\n",
        "        imageDraw.text((x_pos,y_pos), item, font=font, fill=fill)\n",
        "        x_pos = x_pos + font.getsize(item)[0]\n",
        "        imageDraw.text((x_pos,y_pos), \" \", font=font, fill=fill)\n",
        "        x_pos = x_pos + font.getsize(\" \")[0]\n",
        "\n",
        "    #print(blurr_list)\n",
        "    \n",
        "    for item in blurr_list:\n",
        "        pos, width = item\n",
        "        box = (pos,10,pos+width,60)\n",
        "        ic = image.crop(box)\n",
        "        ic = ic.filter(ImageFilter.GaussianBlur(1.5))\n",
        "        image.paste(ic, box)\n",
        "\n",
        "    if is_gaussian == True:\n",
        "        noisy_image = generate_gaussian_noise(np.array(image))\n",
        "        image=Image.fromarray(noisy_image)\n",
        "    \n",
        "    #file_name = data_type +\"/\"+ data_type+\"_\"+str(num_of_generated_samples) + \".jpg\"\n",
        "    file_name = 'data/'+data_type+\"_\"+str(num_of_generated_samples) + \".jpg\"\n",
        "    print(file_name)\n",
        "    image = image.save(file_name)\n",
        "    string = string[:-1]\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "TNKBz6zTuecu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(data_type_num = 0, num=10):\n",
        "    if data_type_num > 4:\n",
        "        print(\"datatype out of range!\")\n",
        "        return\n",
        "    from transformers import pipeline, set_seed\n",
        "    generator = pipeline('text-generation', model='distilgpt2')\n",
        "    set_seed(42)\n",
        "    prompt = [\"A small\", \"I like\", \"He is\", \"She is\", \"It is\", \"I am\", \"you looks\", \"When a\", \"A\", \"Sit down\", \"There are\", \"Food\"]\n",
        "    color_dictionary = {'black':[(255,255,255),(255,255,0)],\\\n",
        "                        'orange':[(255,255,255),(255,255,0),(0,0,0)], \\\n",
        "                        'red':[(255,255,255),(255,255,0),(0,0,0)],\\\n",
        "                        'white':[(0,0,0),(255,0,0),(0,0,255)],\\\n",
        "                        'green':[(0,0,0),(255,255,0),(255,255,255)],\\\n",
        "                        'blue':[(255,255,255),(0,0,0)]}\n",
        "\n",
        "\n",
        "    font_list = ['RobotoMono[wght].ttf','MontserratAlternates-Medium.ttf','KdamThmorPro-Regular.ttf','Joan-Regular.ttf','Roboto-Bold.ttf']\n",
        "    color_list = ['black','orange','red','white','green','blue']\n",
        "    num_of_generated_samples = 0\n",
        "    data_type_list = ['pure','blur','gaussian','blur+gaussian']\n",
        "    data_type = data_type_list[data_type_num]\n",
        "\n",
        "    # csv file open\n",
        "    f = open('data/data_list.csv', 'a', encoding='utf-8', newline='')\n",
        "    #f = open('{0}/{1}_data_list.csv'.format(data_type,data_type), 'w', encoding='utf-8', newline='')\n",
        "    wr = csv.writer(f)\n",
        "    #wr.writerow(['index','text','datatype','background','fill','font'])\n",
        "\n",
        "    \n",
        "    while num_of_generated_samples < num:\n",
        "        result = generator(prompt[random.randrange(0,len(prompt)-1)], max_length=100, num_return_sequences=1)\n",
        "        for item in result:\n",
        "                seq = item['generated_text'].replace(\"\\n\", \" \")\n",
        "                #Getting rid of \\u200b from a string using regular expressions\n",
        "                seq = seq.replace(u'\\u200b', '')\n",
        "                seq = seq.replace(u'\\u200c', '')\n",
        "\n",
        "                seq = seq.replace(\".\",\" \")\n",
        "                seq = seq.replace(\"\\\"\",\"\")\n",
        "                seq = seq.replace(\"  \",\" \")\n",
        "                seq = seq.replace(\"   \",\" \")\n",
        "                seq = seq.replace(\"    \",\" \")\n",
        "                seq = seq.replace(\"     \",\" \")\n",
        "                texts = seq.split(\" \")\n",
        "                index = 0\n",
        "                for i in range(0,10):\n",
        "                    if 6*index+6 > len(texts):\n",
        "                        break\n",
        "\n",
        "                    background = color_list[random.randrange(len(color_list))]\n",
        "                    fill = color_dictionary[background]\n",
        "                    fill = fill[random.randrange(len(fill))]\n",
        "                    #ImageGenerator(texts[6*index:6*index+6], is_rand=is_rand, is_gaussian=is_gaussian, background=background, fill=fill,font_idx=i,num_of_generated_samples=num_of_generated_samples)\n",
        "                    ImageGenerator(texts[6*index:6*index+6], data_type = data_type, background=background, fill=fill,font_idx=i,num_of_generated_samples=num_of_generated_samples)\n",
        "                    #print(num_of_generated_samples,\" \".join(texts[6*index:6*index+6]),\",\",background, fill, font_list[i%len(font_list)])\n",
        "                    #print(\" \".join(texts[6*index:6*index+6]).split(\" \"))\n",
        "                    wr.writerow([num_of_generated_samples,\" \".join(texts[6*index:6*index+6]),data_type,background, fill, font_list[i%len(font_list)]])\n",
        "                    index+=1\n",
        "                    num_of_generated_samples += 1\n",
        "    f.close()\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5qwQaZhu6Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data generation prompt\n",
        "\n",
        "You can generate the dataset with the following command\n",
        "\n",
        "        generate(data_type_num, min_num_of_data)\n",
        "                data_type_num: can select the type of augmentation\n",
        "                    0: 'pure'\n",
        "                    1: 'gaussian'\n",
        "                    2: 'blur'\n",
        "                    3: 'blur+gaussian'\n",
        "                min_num_of_data: determine how many datasets do you make. (more could be made)\n",
        "\n",
        "\n",
        "If you have created the dataset, we can find dataset and .csv file in each directory."
      ],
      "metadata": {
        "id": "a9BRe8xWwwpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm data/*"
      ],
      "metadata": {
        "id": "uZf5FTzuZqzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('data/data_list.csv', 'a', encoding='utf-8', newline='')\n",
        "wr = csv.writer(f)\n",
        "#wr.writerow(['index','text','datatype','background','fill','font'])\n",
        "f.close()\n",
        "\n",
        "generate(0,4000)\n",
        "generate(1,1600)\n",
        "generate(2,1600)\n",
        "generate(3,800)"
      ],
      "metadata": {
        "id": "LRwxVsshuzx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generated dataset\n",
        "\n",
        "We can see generated image it applied augmentation well\n"
      ],
      "metadata": {
        "id": "FjGqyYKyiN4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('data/pure_1.jpg').convert(\"RGB\")\n",
        "imshow(img)"
      ],
      "metadata": {
        "id": "DjsjGPKnuzIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('data/blur_5.jpg').convert(\"RGB\")\n",
        "imshow(img)"
      ],
      "metadata": {
        "id": "8KGVbAffiV0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('data/gaussian_3.jpg').convert(\"RGB\")\n",
        "imshow(img)"
      ],
      "metadata": {
        "id": "r-2c9Peyu4vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('data/blur+gaussian_2.jpg').convert(\"RGB\")\n",
        "imshow(img)"
      ],
      "metadata": {
        "id": "vQl9EDW8u9nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Generate the model (Pretrained)\n",
        "\n",
        "\n",
        "\n",
        "First, we use pre-trained imageEncoder-textDecoder model. which called TrOCR.\n",
        "\n",
        "You can easily download it from hugging face.\n",
        "\n",
        "We use two types of model to compare. Each model fine-tuned with SROIE dataset.\n",
        "\n",
        "1. **trocr-small-printed**: DeiT(Encoder) + UniLM(Decoder) - # params: 61596672\n",
        "2. **trocr-base-printed**: BeiT(Encoder) + Roberta(Decoder) - # params: 333921792"
      ],
      "metadata": {
        "id": "bF-oP71LzYu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**trocr-small-printed**: DeiT(Encoder) + UniLM\n",
        "\n",
        "Doesn't works well when we test with blur+gaussian image"
      ],
      "metadata": {
        "id": "Wi8i1DabhRC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# load image from the IAM database (actually this model is meant to be used on printed text)\n",
        "image = Image.open('data/blur+gaussian_3.jpg').convert(\"RGB\")\n",
        "imshow(np.array(image))\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-printed')\n",
        "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-small-printed')\n",
        "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "generated_ids = model.generate(pixel_values)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(\"\\n\\n\\n\\ngenerated_text:{}\".format(generated_text))"
      ],
      "metadata": {
        "id": "4_Yi5FrvzmuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**trocr-base-printed**: BeiT(Encoder) + Roberta(Decoder)\n",
        "\n",
        "\n",
        "Works well when we test with blur+gaussian image"
      ],
      "metadata": {
        "id": "g6twlJichh0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load image from the IAM database (actually this model is meant to be used on printed text)\n",
        "image = Image.open('data/blur+gaussian_3.jpg').convert(\"RGB\")\n",
        "imshow(np.array(image))\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')\n",
        "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')\n",
        "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "generated_ids = model.generate(pixel_values)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(\"\\n\\n\\n\\ngenerated_text:{}\".format(generated_text))"
      ],
      "metadata": {
        "id": "ik54VlHL2wuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generate other model - ViT+LSTM\n",
        "\n",
        "We generate other model to compare with the models below."
      ],
      "metadata": {
        "id": "j9LFI9NG9H6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Generate Dataloader\n",
        "\n",
        "We need to convert character sequence to tensor so that torch can handle it.\n"
      ],
      "metadata": {
        "id": "ALS4ZMOf9gYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* One-hot encoding - we convert each character of the sequence into one-hot vector."
      ],
      "metadata": {
        "id": "0IjdMdQu9918"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, PackedSequence\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import string\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "toT = ToTensor()\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "B9SIUmGcBwCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len('TO SEE WHAT\\''))\n",
        "\n",
        "tensor_list = []\n",
        "for item in ('TO SEE WHAT\\''):\n",
        "    #print((ord(item)),F.one_hot(torch.tensor(ord(item)), num_classes=128))\n",
        "    tensor_list.append((F.one_hot(torch.tensor(ord(item)), num_classes=128)))\n",
        "tensors = torch.stack(tensor_list)\n",
        "\n",
        "print(tensors[0])"
      ],
      "metadata": {
        "id": "CS3Nd8GA-g6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* convert image into tensor - convert image into tensor"
      ],
      "metadata": {
        "id": "mXmbfd99-YgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('data/blur+gaussian_3.jpg').convert(\"RGB\")\n",
        "img_resize = image.resize((256, 256))\n",
        "print(type(img_resize))\n",
        "print(type(image))\n",
        "imshow(np.array(img_resize))\n",
        "toT = ToTensor()\n",
        "toT(image)"
      ],
      "metadata": {
        "id": "Zny112MjBxYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class image_text_Dataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): csv 파일의 경로\n",
        "            root_dir (string): 이미지가 존재하는 디렉토리 경로\n",
        "        \"\"\"\n",
        "        self.data_list = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #img_path = self.root_dir + str(idx) + '.jpg'\n",
        "        #img = Image.open(img_path).convert(\"RGB\")\n",
        "        #img_transformed = toT(img.resize((224, 224)))\n",
        "        text = self.data_list.values[idx][1]\n",
        "        img_path = self.root_dir + imgset.data_list.values[idx][2] +'_' +str(imgset.data_list.values[idx][0])+'.jpg' \n",
        "        \n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_transformed = toT(img.resize((224, 224)))\n",
        "        tensor_list = []\n",
        "        for item in text:\n",
        "            tensor_list.append(ord(item))\n",
        "            #tensor_list.append((F.one_hot(torch.tensor(ord(item)), num_classes=128)))\n",
        "        text_tensors = torch.Tensor(tensor_list)\n",
        "\n",
        "        return img_transformed, text_tensors\n",
        "\n",
        "imgset = image_text_Dataset(csv_file = 'data/data_list.csv',\n",
        "                                   root_dir='data/')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img_transformed, target = imgset[1]"
      ],
      "metadata": {
        "id": "egPG90rbBuRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_text_Dataset(csv_file = 'data/data_list.csv',\n",
        "                                   root_dir='data/')\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                                   batch_size=batch_size,\n",
        "                                   shuffle=True)\n",
        "\n",
        "# batch_iterator = iter(train_dataloader)\n",
        "# images = next(batch_iterator)"
      ],
      "metadata": {
        "id": "ZQwAre0aKMAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2. Define other model"
      ],
      "metadata": {
        "id": "y5GVT-qG-6XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "KtyYy2Id-8Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "# model = timm.create_model('resnet50d', pretrained=True)\n",
        "model = timm.create_model('vit_small_r26_s32_224_in21k', pretrained=True)\n",
        "#model1 = timm.create_model('resnet50d', pretrained=True)\n",
        "o = model.forward_features(torch.randn(2, 3, 224, 224))\n",
        "#o1 = model1.forward_features(torch.randn(2, 3, 224, 224))\n",
        "print(o.shape)\n",
        "#print(o1.shape)\n"
      ],
      "metadata": {
        "id": "SaHxHeCmCNSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from timm.data import resolve_data_config\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TextRecognizer(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_size,  embedding_size, n_layers=1):\n",
        "        super(TextRecognizer, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.embedding_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x=x.unsqueeze(2)\n",
        "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
        "        out = self.dropout(out)\n",
        "        x = self.fc(out)\n",
        "        return x, (ht1, ct1)\n",
        "    \n",
        "    def init_hidden(self, batch_size = 1):\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
      ],
      "metadata": {
        "id": "GzwY8NFGyiho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = TextRecognizer(hidden_size=384, embedding_size=1, n_layers=1)\n",
        "model.to(device)\n",
        "vision_model = timm.create_model('vit_small_r26_s32_224_in21k', pretrained=True)\n",
        "vision_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    patience=5, \n",
        "    verbose=True, \n",
        "    factor=0.5\n",
        ")\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size = 1\n",
        "loss_avg = []\n"
      ],
      "metadata": {
        "id": "lMLxI7UtBNAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(n_epochs)):\n",
        "    for img, text_tensor in train_dataloader:\n",
        "        img = img.to(device)\n",
        "        zero = torch.zeros(batch_size,1)\n",
        "        target = text_tensor\n",
        "        input = torch.cat([zero,target],dim=1)\n",
        "        print(input.shape)\n",
        "        #hidden = model.init_hidden(batch_size = 1)\n",
        "        \n",
        "        input = input.permute(1, 0).to(device)\n",
        "        target = target.permute(1, 0).to(device)\n",
        "        hidden = vision_model.forward_features(img).unsqueeze(1)\n",
        "        hidden = (hidden, hidden)\n",
        "        #print(target.shape)\n",
        "        #print(hidden[0].shape)\n",
        "        #print(o.shape)\n",
        "\n",
        "        output,hidden = model(input,hidden)\n",
        "\n",
        "\n",
        "        loss = criterion(output[:-1].squeeze(1), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "MXVr0OakBOgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_text = ' '\n",
        "\n",
        "imgset = image_text_Dataset(csv_file = 'data/data_list.csv',\n",
        "                                   root_dir='data/')\n",
        "\n",
        "print(imgset.data_list)\n",
        "img_transformed, target = imgset[10]\n",
        "img_transformed = img_transformed.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "hidden = vision_model.forward_features(img_transformed.unsqueeze(0)).unsqueeze(1)\n",
        "hidden = (hidden, hidden)\n",
        "\n",
        "output,hidden = model(input,hidden)\n",
        "string = ''\n",
        "for i in range(0,len(output)-1):\n",
        "    string = string + (chr(round(output[i].item()+67)))\n",
        "\n",
        "print(string)\n",
        "\n",
        "root_dir = 'data/'\n",
        "text = imgset.data_list.values[10][1]\n",
        "img_path = root_dir + imgset.data_list.values[10][2] +'_' +str(imgset.data_list.values[10][0])+'.jpg' \n",
        "\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "imshow(img)\n"
      ],
      "metadata": {
        "id": "OVwTluKM1tLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}